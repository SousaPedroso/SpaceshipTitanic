{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "\n",
    "This sections aims to provide insights into the data and the problem we are dealing with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "spaceship_df = pd.read_csv(\"/kaggle/input/spaceship-titanic/train.csv\")\n",
    "# Check how data is organized\n",
    "spaceship_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a mix between the types, we will check the general informations about the data and count the number of missing values. Initially we will just drop this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spaceship_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation between numerical columns\n",
    "spaceship_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spaceship_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop missing values and check the difference\n",
    "non_nan_spaceship_df = spaceship_df.dropna()\n",
    "print(len(spaceship_df)-len(non_nan_spaceship_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite the number of missing values be small, this is number is correspodent to multiple observations, removing a lot of data to we train. We will make some improvements later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentual of removed data\n",
    "print(100*(len(spaceship_df)-len(non_nan_spaceship_df))/len(spaceship_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some numerical columns demonstrated be relationed with each other, but the categorical data we will have a closer looking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Home Planet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x=\"HomePlanet\", col=\"Transported\", kind=\"count\", ci=None, data=non_nan_spaceship_df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CryoSleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x=\"CryoSleep\", col=\"Transported\", kind=\"count\", ci=None, data=non_nan_spaceship_df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x=\"Destination\", col=\"Transported\", kind=\"count\", ci=None, data=non_nan_spaceship_df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x=\"VIP\", col=\"Transported\", kind=\"count\", ci=None, data=non_nan_spaceship_df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relationship with the Home Planet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x=\"VIP\", col=\"HomePlanet\", kind=\"count\", ci=None, data=non_nan_spaceship_df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Cabin column is composed by deck, num and side. We will explore these attributes individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cabin_deck(cabin):\n",
    "    if type(cabin) is str:\n",
    "        return cabin.split('/')[0]\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "def get_cabin_num(cabin):\n",
    "    if type(cabin) is str:\n",
    "        return cabin.split('/')[1]\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "def get_cabin_side(cabin):\n",
    "    if type(cabin) is str:\n",
    "        return cabin.split('/')[2]\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "cabin_deck = non_nan_spaceship_df.Cabin.map(get_cabin_deck)\n",
    "cabin_num = non_nan_spaceship_df.Cabin.map(get_cabin_num)\n",
    "cabin_side = non_nan_spaceship_df.Cabin.map(get_cabin_side)\n",
    "del non_nan_spaceship_df['Cabin']\n",
    "non_nan_spaceship_df.insert(len(non_nan_spaceship_df.columns) - 1, 'CabinDeck', cabin_deck)\n",
    "non_nan_spaceship_df.insert(len(non_nan_spaceship_df.columns) - 1, 'CabinNum', cabin_num)\n",
    "non_nan_spaceship_df.insert(len(non_nan_spaceship_df.columns) - 1, 'CabinSide', cabin_side)\n",
    "non_nan_spaceship_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible values for a Cabin number are infeasible to plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_cabin_num = np.unique(non_nan_spaceship_df['CabinNum'].values, return_counts=True)\n",
    "print(unique_cabin_num, len(unique_cabin_num[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x=\"CabinDeck\", col=\"Transported\", kind=\"count\", ci=None, data=non_nan_spaceship_df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x=\"CabinSide\", col=\"Transported\", kind=\"count\", ci=None, data=non_nan_spaceship_df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides that, a possibility would be a Last name for a person, but we checked that the unique values is to huge for preprocessing for the Machine Learning algorithms. We will ignore this attribute for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_name(name):\n",
    "    if type(name) is str:\n",
    "        return name.split()[1]\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "def get_first_name(name):\n",
    "    if type(name) is str:\n",
    "        return name.split()[0]\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "first_name = non_nan_spaceship_df.Name.map(get_first_name)\n",
    "last_name = non_nan_spaceship_df.Name.map(get_last_name)\n",
    "del non_nan_spaceship_df['Name']\n",
    "non_nan_spaceship_df.insert(len(non_nan_spaceship_df.columns) - 1, 'FirstName', first_name)\n",
    "non_nan_spaceship_df.insert(len(non_nan_spaceship_df.columns) - 1, 'LastName', last_name)\n",
    "non_nan_spaceship_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.catplot(x=\"LastName\", col=\"Transported\", kind=\"count\", ci=None, data=non_nan_spaceship_df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_last_name = np.unique(non_nan_spaceship_df['LastName'].values, return_counts=True)\n",
    "print(unique_last_name, len(unique_last_name[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The PassengerId contains the group's number for each person. It is a possibility of significant attribute too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_group(id):\n",
    "    if type(id) is str:\n",
    "        return id.split('_')[0]\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "group = non_nan_spaceship_df.PassengerId.map(get_group)\n",
    "del non_nan_spaceship_df['PassengerId']\n",
    "non_nan_spaceship_df.insert(0, 'IdGroup', group)\n",
    "non_nan_spaceship_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same situation as LastName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_group = np.unique(non_nan_spaceship_df['IdGroup'].values, return_counts=True)\n",
    "print(unique_group, len(unique_group[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "This sections is divided according to the ideas used to the models Random Forest (RF) and Multi Layer Perceptron (MLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 largest correlations with Transported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = non_nan_spaceship_df[\"Transported\"].values\n",
    "x = np.concatenate((non_nan_spaceship_df[\"Spa\"].values.reshape((len(non_nan_spaceship_df[\"Spa\"].values), 1)),\n",
    "                    non_nan_spaceship_df[\"VRDeck\"].values.reshape((len(non_nan_spaceship_df[\"VRDeck\"].values), 1)),\n",
    "                    non_nan_spaceship_df[\"RoomService\"].values.reshape((len(non_nan_spaceship_df[\"RoomService\"].values), 1))\n",
    "                   ), axis=1)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=32764)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All numeric columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = non_nan_spaceship_df[[\"Age\", \"RoomService\", \"FoodCourt\", \"ShoppingMall\", \"Spa\", \"VRDeck\"]]\n",
    "y = non_nan_spaceship_df[\"Transported\"]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=32764)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most significative features and categoric columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get numeric columns\n",
    "x = np.concatenate((non_nan_spaceship_df[\"Age\"].values.reshape((len(non_nan_spaceship_df[\"Age\"].values), 1, 1)),\n",
    "                    non_nan_spaceship_df[\"RoomService\"].values.reshape((len(non_nan_spaceship_df[\"RoomService\"].values), 1, 1)),\n",
    "                    non_nan_spaceship_df[\"FoodCourt\"].values.reshape((len(non_nan_spaceship_df[\"FoodCourt\"].values), 1, 1)),\n",
    "                    non_nan_spaceship_df[\"ShoppingMall\"].values.reshape((len(non_nan_spaceship_df[\"ShoppingMall\"].values), 1, 1)),\n",
    "                    non_nan_spaceship_df[\"Spa\"].values.reshape((len(non_nan_spaceship_df[\"Spa\"].values), 1, 1)),\n",
    "                    non_nan_spaceship_df[\"VRDeck\"].values.reshape((len(non_nan_spaceship_df[\"VRDeck\"].values), 1, 1))\n",
    "                   ), axis=1)\n",
    "\n",
    "y = non_nan_spaceship_df[\"Transported\"].values\n",
    "\n",
    "# Cryosleep and home planet\n",
    "x_categorical = np.concatenate((non_nan_spaceship_df[\"CryoSleep\"].values.reshape((len(non_nan_spaceship_df[\"CryoSleep\"]), 1)),\n",
    "                               non_nan_spaceship_df[\"HomePlanet\"].values.reshape((len(non_nan_spaceship_df[\"HomePlanet\"]), 1))),\n",
    "                               axis=1)\n",
    "\n",
    "x_categorical[:, 0] = np.where(x_categorical[:, 0] == True, 2, 0)\n",
    "x_categorical[:, 1] = np.where(x_categorical[:, 1] == 'Earth', 3,\n",
    "                               np.where(x_categorical[:, 1] == 'Europa', 2, 1))\n",
    "\n",
    "x = np.concatenate((x.reshape((x.shape[0], 6)), x_categorical), axis=1)\n",
    "x = x.astype(np.float16)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=32764)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Including IdGroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get numeric columns\n",
    "x = np.concatenate((non_nan_spaceship_df[\"IdGroup\"].values.reshape((len(non_nan_spaceship_df[\"IdGroup\"].values), 1, 1)),\n",
    "                    non_nan_spaceship_df[\"Age\"].values.reshape((len(non_nan_spaceship_df[\"Age\"].values), 1, 1)),\n",
    "                    non_nan_spaceship_df[\"RoomService\"].values.reshape((len(non_nan_spaceship_df[\"RoomService\"].values), 1, 1)),\n",
    "                    non_nan_spaceship_df[\"FoodCourt\"].values.reshape((len(non_nan_spaceship_df[\"FoodCourt\"].values), 1, 1)),\n",
    "                    non_nan_spaceship_df[\"ShoppingMall\"].values.reshape((len(non_nan_spaceship_df[\"ShoppingMall\"].values), 1, 1)),\n",
    "                    non_nan_spaceship_df[\"Spa\"].values.reshape((len(non_nan_spaceship_df[\"Spa\"].values), 1, 1)),\n",
    "                    non_nan_spaceship_df[\"VRDeck\"].values.reshape((len(non_nan_spaceship_df[\"VRDeck\"].values), 1, 1))\n",
    "                   ), axis=1)\n",
    "\n",
    "y = non_nan_spaceship_df[\"Transported\"].values\n",
    "\n",
    "# Cryosleep and home planet\n",
    "x_categorical = np.concatenate((non_nan_spaceship_df[\"CryoSleep\"].values.reshape((len(non_nan_spaceship_df[\"CryoSleep\"]), 1)),\n",
    "                               non_nan_spaceship_df[\"HomePlanet\"].values.reshape((len(non_nan_spaceship_df[\"HomePlanet\"]), 1))),\n",
    "                               axis=1)\n",
    "\n",
    "x_categorical[:, 0] = np.where(x_categorical[:, 0] == True, 2, 0)\n",
    "x_categorical[:, 1] = np.where(x_categorical[:, 1] == 'Earth', 3,\n",
    "                               np.where(x_categorical[:, 1] == 'Europa', 2, 1))\n",
    "\n",
    "x = np.concatenate((x.reshape((x.shape[0], 7)), x_categorical), axis=1)\n",
    "x = x.astype(np.float16)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=32764)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 largest correlations with Transported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.concatenate((non_nan_spaceship_df[\"RoomService\"].values.reshape((len(non_nan_spaceship_df[\"RoomService\"].values), 1, 1)),\n",
    "                    non_nan_spaceship_df[\"Spa\"].values.reshape((len(non_nan_spaceship_df[\"Spa\"].values), 1, 1)),\n",
    "                    non_nan_spaceship_df[\"VRDeck\"].values.reshape((len(non_nan_spaceship_df[\"VRDeck\"].values), 1, 1))\n",
    "                   ), axis=1)\n",
    "\n",
    "y = non_nan_spaceship_df[\"Transported\"].values\n",
    "\n",
    "room_normalizer = Normalizer().fit(x[:, 0])\n",
    "spa_normalizer = Normalizer().fit(x[:, 1])\n",
    "vr_normalizer = Normalizer().fit(x[:, 2])\n",
    "\n",
    "x[:, 0] = room_normalizer.transform(x[:, 0])\n",
    "x[:, 1] = spa_normalizer.transform(x[:, 1])\n",
    "x[:, 2] = vr_normalizer.transform(x[:, 2])\n",
    "\n",
    "x = x.reshape((x.shape[0], 3))\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=32764)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All numeric columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.concatenate((non_nan_spaceship_df[\"Age\"].values.reshape((len(non_nan_spaceship_df[\"Age\"].values), 1, 1)),\n",
    "                    non_nan_spaceship_df[\"RoomService\"].values.reshape((len(non_nan_spaceship_df[\"RoomService\"].values), 1, 1)),\n",
    "                    non_nan_spaceship_df[\"FoodCourt\"].values.reshape((len(non_nan_spaceship_df[\"FoodCourt\"].values), 1, 1)),\n",
    "                    non_nan_spaceship_df[\"ShoppingMall\"].values.reshape((len(non_nan_spaceship_df[\"ShoppingMall\"].values), 1, 1)),\n",
    "                    non_nan_spaceship_df[\"Spa\"].values.reshape((len(non_nan_spaceship_df[\"Spa\"].values), 1, 1)),\n",
    "                    non_nan_spaceship_df[\"VRDeck\"].values.reshape((len(non_nan_spaceship_df[\"VRDeck\"].values), 1, 1))\n",
    "                   ), axis=1)\n",
    "\n",
    "y = non_nan_spaceship_df[\"Transported\"].values\n",
    "\n",
    "age_normalizer = Normalizer().fit(x[:, 0])\n",
    "room_normalizer = Normalizer().fit(x[:, 1])\n",
    "food_normalizer = Normalizer().fit(x[:, 2])\n",
    "shopping_normalizer = Normalizer().fit(x[:, 3])\n",
    "spa_normalizer = Normalizer().fit(x[:, 4])\n",
    "vr_normalizer = Normalizer().fit(x[:, 5])\n",
    "\n",
    "x[:, 0] = age_normalizer.transform(x[:, 0])\n",
    "x[:, 1] = room_normalizer.transform(x[:, 1])\n",
    "x[:, 2] = food_normalizer.transform(x[:, 2])\n",
    "x[:, 3] = shopping_normalizer.transform(x[:, 3])\n",
    "x[:, 4] = spa_normalizer.transform(x[:, 4])\n",
    "x[:, 5] = vr_normalizer.transform(x[:, 5])\n",
    "\n",
    "x = x.reshape((x.shape[0], 6))\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=32764)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most significative features and categoric columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get numeric columns\n",
    "x = np.concatenate((non_nan_spaceship_df[\"RoomService\"].values.reshape((len(non_nan_spaceship_df[\"RoomService\"].values), 1, 1)),\n",
    "                    non_nan_spaceship_df[\"Spa\"].values.reshape((len(non_nan_spaceship_df[\"Spa\"].values), 1, 1)),\n",
    "                    non_nan_spaceship_df[\"VRDeck\"].values.reshape((len(non_nan_spaceship_df[\"VRDeck\"].values), 1, 1))\n",
    "                   ), axis=1)\n",
    "\n",
    "y = non_nan_spaceship_df[\"Transported\"].values\n",
    "\n",
    "room_normalizer = Normalizer().fit(x[:, 0])\n",
    "spa_normalizer = Normalizer().fit(x[:, 1])\n",
    "vr_normalizer = Normalizer().fit(x[:, 2])\n",
    "\n",
    "x[:, 0] = room_normalizer.transform(x[:, 0])\n",
    "x[:, 1] = spa_normalizer.transform(x[:, 1])\n",
    "x[:, 2] = vr_normalizer.transform(x[:, 2])\n",
    "\n",
    "# Cryosleep and home planet\n",
    "x_categorical = np.concatenate((non_nan_spaceship_df[\"CryoSleep\"].values.reshape((len(non_nan_spaceship_df[\"CryoSleep\"]), 1)),\n",
    "                               non_nan_spaceship_df[\"HomePlanet\"].values.reshape((len(non_nan_spaceship_df[\"HomePlanet\"]), 1))),\n",
    "                               axis=1)\n",
    "\n",
    "x_categorical[:, 0] = np.where(x_categorical[:, 0] == True, 2, 0)\n",
    "x_categorical[:, 1] = np.where(x_categorical[:, 1] == 'Earth', 3,\n",
    "                               np.where(x_categorical[:, 1] == 'Europa', 2, 1))\n",
    "\n",
    "x = np.concatenate((x.reshape((x.shape[0], 3)), x_categorical), axis=1)\n",
    "x = x.astype(np.float16)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=32764)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inclusion of IdGroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get numeric columns\n",
    "x = np.concatenate((non_nan_spaceship_df[\"IdGroup\"].values.reshape((len(non_nan_spaceship_df[\"IdGroup\"].values), 1, 1)),\n",
    "                    non_nan_spaceship_df[\"RoomService\"].values.reshape((len(non_nan_spaceship_df[\"RoomService\"].values), 1, 1)),\n",
    "                    non_nan_spaceship_df[\"Spa\"].values.reshape((len(non_nan_spaceship_df[\"Spa\"].values), 1, 1)),\n",
    "                    non_nan_spaceship_df[\"VRDeck\"].values.reshape((len(non_nan_spaceship_df[\"VRDeck\"].values), 1, 1))\n",
    "                   ), axis=1)\n",
    "\n",
    "y = non_nan_spaceship_df[\"Transported\"].values\n",
    "\n",
    "group_normalizer = Normalizer().fit(x[:, 0])\n",
    "room_normalizer = Normalizer().fit(x[:, 1])\n",
    "spa_normalizer = Normalizer().fit(x[:, 2])\n",
    "vr_normalizer = Normalizer().fit(x[:, 3])\n",
    "\n",
    "x[:, 0] = group_normalizer.transform(x[:, 0])\n",
    "x[:, 1] = room_normalizer.transform(x[:, 1])\n",
    "x[:, 2] = spa_normalizer.transform(x[:, 2])\n",
    "x[:, 3] = vr_normalizer.transform(x[:, 3])\n",
    "\n",
    "# Cryosleep and home planet\n",
    "x_categorical = np.concatenate((non_nan_spaceship_df[\"CryoSleep\"].values.reshape((len(non_nan_spaceship_df[\"CryoSleep\"]), 1)),\n",
    "                               non_nan_spaceship_df[\"HomePlanet\"].values.reshape((len(non_nan_spaceship_df[\"HomePlanet\"]), 1))),\n",
    "                               axis=1)\n",
    "\n",
    "\n",
    "x_categorical[:, 0] = np.where(x_categorical[:, 0] == True, 2, 0)\n",
    "x_categorical[:, 1] = np.where(x_categorical[:, 1] == 'Earth', 3,\n",
    "                               np.where(x_categorical[:, 1] == 'Europa', 2, 1))\n",
    "\n",
    "x = np.concatenate((x.reshape((x.shape[0], 4)), x_categorical), axis=1)\n",
    "x = x.astype(np.float16)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=32764)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "This section trains the models and provides the performance over the test set for each algorithm (the choosen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducibility\n",
    "rf = RandomForestClassifier(random_state=32764)\n",
    "\n",
    "rf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, rf.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducibility\n",
    "mlp = MLPClassifier(random_state=32764)\n",
    "\n",
    "mlp.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, mlp.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission\n",
    "\n",
    "This section demonstrate how the data of submission was preprocessed according to each proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 largest correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "test_df = pd.read_csv(\"../input/spaceship-titanic/test.csv\")\n",
    "x = test_df[[\"RoomService\", \"Spa\", \"VRDeck\"]]\n",
    "\n",
    "x[\"RoomService\"].fillna(x[\"RoomService\"].mean(skipna=True), inplace=True)\n",
    "x[\"Spa\"].fillna(x[\"Spa\"].mean(skipna=True), inplace=True)\n",
    "x[\"VRDeck\"].fillna(x[\"VRDeck\"].mean(skipna=True), inplace=True)\n",
    "\n",
    "x = np.concatenate((x[\"Spa\"].values.reshape((len(x[\"Spa\"].values), 1)),\n",
    "                    x[\"VRDeck\"].values.reshape((len(x[\"VRDeck\"].values), 1)),\n",
    "                    x[\"RoomService\"].values.reshape((len(x[\"RoomService\"].values), 1))\n",
    "                   ), axis=1)\n",
    "\n",
    "y = rf.predict(x)\n",
    "submission_df = pd.DataFrame({\"PassengerId\": test_df.PassengerId, \"Transported\": y})\n",
    "submission_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All numeric columns, replacing missing values for the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "test_df = pd.read_csv(\"../input/spaceship-titanic/test.csv\")\n",
    "x = test_df[[\"Age\", \"RoomService\", \"FoodCourt\", \"ShoppingMall\", \"Spa\", \"VRDeck\"]]\n",
    "\n",
    "x[\"Age\"].fillna(x[\"Age\"].mean(skipna=True), inplace=True)\n",
    "x[\"RoomService\"].fillna(x[\"RoomService\"].mean(skipna=True), inplace=True)\n",
    "x[\"FoodCourt\"].fillna(x[\"FoodCourt\"].mean(skipna=True), inplace=True)\n",
    "x[\"ShoppingMall\"].fillna(x[\"ShoppingMall\"].mean(skipna=True), inplace=True)\n",
    "x[\"Spa\"].fillna(x[\"Spa\"].mean(skipna=True), inplace=True)\n",
    "x[\"VRDeck\"].fillna(x[\"VRDeck\"].mean(skipna=True), inplace=True)\n",
    "\n",
    "y = rf.predict(x)\n",
    "submission_df = pd.DataFrame({\"PassengerId\": test_df.PassengerId, \"Transported\": y})\n",
    "submission_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All numeric columns and categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "test_df = pd.read_csv(\"../input/spaceship-titanic/test.csv\")\n",
    "x = test_df[[\"Age\", \"RoomService\", \"FoodCourt\", \"ShoppingMall\", \"Spa\", \"VRDeck\", \"CryoSleep\", \"HomePlanet\"]]\n",
    "\n",
    "x[\"Age\"].fillna(x[\"Age\"].mean(skipna=True), inplace=True)\n",
    "x[\"RoomService\"].fillna(x[\"RoomService\"].mean(skipna=True), inplace=True)\n",
    "x[\"FoodCourt\"].fillna(x[\"FoodCourt\"].mean(skipna=True), inplace=True)\n",
    "x[\"ShoppingMall\"].fillna(x[\"ShoppingMall\"].mean(skipna=True), inplace=True)\n",
    "x[\"Spa\"].fillna(x[\"Spa\"].mean(skipna=True), inplace=True)\n",
    "x[\"VRDeck\"].fillna(x[\"VRDeck\"].mean(skipna=True), inplace=True)\n",
    "\n",
    "x[\"CryoSleep\"] = np.where(x[\"CryoSleep\"].values == True, 2, np.where(x[\"CryoSleep\"].values == False, 0, 1))\n",
    "x[\"HomePlanet\"] = np.where(x[\"HomePlanet\"].values == 'Earth', 3,\n",
    "                               np.where(x[\"HomePlanet\"].values == 'Europa', 2,\n",
    "                                       np.where(x[\"HomePlanet\"].values == 'Mars', 1, 0)))\n",
    "\n",
    "x = np.concatenate((x[\"Age\"].values.reshape((len(x[\"Age\"].values), 1, 1)),\n",
    "                    x[\"RoomService\"].values.reshape((len(x[\"RoomService\"].values), 1, 1)),\n",
    "                    x[\"FoodCourt\"].values.reshape((len(x[\"FoodCourt\"].values), 1, 1)),\n",
    "                    x[\"ShoppingMall\"].values.reshape((len(x[\"ShoppingMall\"].values), 1, 1)),\n",
    "                    x[\"Spa\"].values.reshape((len(x[\"Spa\"].values), 1, 1)),\n",
    "                    x[\"VRDeck\"].values.reshape((len(x[\"VRDeck\"].values), 1, 1)),\n",
    "                    x[\"CryoSleep\"].values.reshape((len(x[\"CryoSleep\"].values), 1, 1)),\n",
    "                    x[\"HomePlanet\"].values.reshape((len(x[\"HomePlanet\"].values), 1, 1))\n",
    "                   ), axis=1)\n",
    "\n",
    "\n",
    "# reshape\n",
    "x = x.reshape((x.shape[0], 8)).astype(np.float16)\n",
    "\n",
    "y = rf.predict(x)\n",
    "submission_df = pd.DataFrame({\"PassengerId\": test_df.PassengerId, \"Transported\": y})\n",
    "submission_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inclusion of IdGroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "test_df = pd.read_csv(\"../input/spaceship-titanic/test.csv\")\n",
    "x = test_df[[\"PassengerId\", \"Age\", \"RoomService\", \"FoodCourt\", \"ShoppingMall\", \"Spa\", \"VRDeck\", \"CryoSleep\", \"HomePlanet\"]]\n",
    "\n",
    "group = x.PassengerId.map(get_group)\n",
    "del x['PassengerId']\n",
    "x.insert(0, 'IdGroup', group)\n",
    "\n",
    "x[\"Age\"].fillna(x[\"Age\"].mean(skipna=True), inplace=True)\n",
    "x[\"RoomService\"].fillna(x[\"RoomService\"].mean(skipna=True), inplace=True)\n",
    "x[\"FoodCourt\"].fillna(x[\"FoodCourt\"].mean(skipna=True), inplace=True)\n",
    "x[\"ShoppingMall\"].fillna(x[\"ShoppingMall\"].mean(skipna=True), inplace=True)\n",
    "x[\"Spa\"].fillna(x[\"Spa\"].mean(skipna=True), inplace=True)\n",
    "x[\"VRDeck\"].fillna(x[\"VRDeck\"].mean(skipna=True), inplace=True)\n",
    "\n",
    "x[\"CryoSleep\"] = np.where(x[\"CryoSleep\"].values == True, 2, np.where(x[\"CryoSleep\"].values == False, 0, 1))\n",
    "x[\"HomePlanet\"] = np.where(x[\"HomePlanet\"].values == 'Earth', 3,\n",
    "                               np.where(x[\"HomePlanet\"].values == 'Europa', 2,\n",
    "                                       np.where(x[\"HomePlanet\"].values == 'Mars', 1, 0)))\n",
    "\n",
    "x = np.concatenate((x[\"IdGroup\"].values.reshape((len(x[\"IdGroup\"].values), 1, 1)),\n",
    "                    x[\"Age\"].values.reshape((len(x[\"Age\"].values), 1, 1)),\n",
    "                    x[\"RoomService\"].values.reshape((len(x[\"RoomService\"].values), 1, 1)),\n",
    "                    x[\"FoodCourt\"].values.reshape((len(x[\"FoodCourt\"].values), 1, 1)),\n",
    "                    x[\"ShoppingMall\"].values.reshape((len(x[\"ShoppingMall\"].values), 1, 1)),\n",
    "                    x[\"Spa\"].values.reshape((len(x[\"Spa\"].values), 1, 1)),\n",
    "                    x[\"VRDeck\"].values.reshape((len(x[\"VRDeck\"].values), 1, 1)),\n",
    "                    x[\"CryoSleep\"].values.reshape((len(x[\"CryoSleep\"].values), 1, 1)),\n",
    "                    x[\"HomePlanet\"].values.reshape((len(x[\"HomePlanet\"].values), 1, 1))\n",
    "                   ), axis=1)\n",
    "\n",
    "\n",
    "# reshape\n",
    "x = x.reshape((x.shape[0], 9)).astype(np.float16)\n",
    "\n",
    "y = rf.predict(x)\n",
    "submission_df = pd.DataFrame({\"PassengerId\": test_df.PassengerId, \"Transported\": y})\n",
    "submission_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 largest correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "test_df = pd.read_csv(\"../input/spaceship-titanic/test.csv\")\n",
    "x = test_df[[\"RoomService\", \"Spa\", \"VRDeck\"]]\n",
    "\n",
    "x[\"RoomService\"].fillna(x[\"RoomService\"].mean(skipna=True), inplace=True)\n",
    "x[\"Spa\"].fillna(x[\"Spa\"].mean(skipna=True), inplace=True)\n",
    "x[\"VRDeck\"].fillna(x[\"VRDeck\"].mean(skipna=True), inplace=True)\n",
    "\n",
    "x = np.concatenate((x[\"RoomService\"].values.reshape((len(x[\"RoomService\"].values), 1, 1)),\n",
    "                    x[\"Spa\"].values.reshape((len(x[\"Spa\"].values), 1, 1)),\n",
    "                    x[\"VRDeck\"].values.reshape((len(x[\"VRDeck\"].values), 1, 1))\n",
    "                   ), axis=1)\n",
    "\n",
    "# Normalize the features\n",
    "x[:, 0] = room_normalizer.transform(x[:, 0])\n",
    "x[:, 1] = spa_normalizer.transform(x[:, 1])\n",
    "x[:, 2] = vr_normalizer.transform(x[:, 2])\n",
    "\n",
    "# reshape\n",
    "x = x.reshape((x.shape[0], 3))\n",
    "\n",
    "y = mlp.predict(x)\n",
    "submission_df = pd.DataFrame({\"PassengerId\": test_df.PassengerId, \"Transported\": y})\n",
    "submission_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All numeric columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "test_df = pd.read_csv(\"../input/spaceship-titanic/test.csv\")\n",
    "x = test_df[[\"Age\", \"RoomService\", \"FoodCourt\", \"ShoppingMall\", \"Spa\", \"VRDeck\"]]\n",
    "\n",
    "x[\"Age\"].fillna(x[\"Age\"].mean(skipna=True), inplace=True)\n",
    "x[\"RoomService\"].fillna(x[\"RoomService\"].mean(skipna=True), inplace=True)\n",
    "x[\"FoodCourt\"].fillna(x[\"FoodCourt\"].mean(skipna=True), inplace=True)\n",
    "x[\"ShoppingMall\"].fillna(x[\"ShoppingMall\"].mean(skipna=True), inplace=True)\n",
    "x[\"Spa\"].fillna(x[\"Spa\"].mean(skipna=True), inplace=True)\n",
    "x[\"VRDeck\"].fillna(x[\"VRDeck\"].mean(skipna=True), inplace=True)\n",
    "\n",
    "x = np.concatenate((x[\"Age\"].values.reshape((len(x[\"Age\"].values), 1, 1)),\n",
    "                    x[\"RoomService\"].values.reshape((len(x[\"RoomService\"].values), 1, 1)),\n",
    "                    x[\"FoodCourt\"].values.reshape((len(x[\"FoodCourt\"].values), 1, 1)),\n",
    "                    x[\"ShoppingMall\"].values.reshape((len(x[\"ShoppingMall\"].values), 1, 1)),\n",
    "                    x[\"Spa\"].values.reshape((len(x[\"Spa\"].values), 1, 1)),\n",
    "                    x[\"VRDeck\"].values.reshape((len(x[\"VRDeck\"].values), 1, 1))\n",
    "                   ), axis=1)\n",
    "\n",
    "# Normalize the features\n",
    "x[:, 0] = age_normalizer.transform(x[:, 0])\n",
    "x[:, 1] = room_normalizer.transform(x[:, 1])\n",
    "x[:, 2] = food_normalizer.transform(x[:, 2])\n",
    "x[:, 3] = shopping_normalizer.transform(x[:, 3])\n",
    "x[:, 4] = spa_normalizer.transform(x[:, 4])\n",
    "x[:, 5] = vr_normalizer.transform(x[:, 5])\n",
    "\n",
    "# reshape\n",
    "x = x.reshape((x.shape[0], 6))\n",
    "\n",
    "y = mlp.predict(x)\n",
    "submission_df = pd.DataFrame({\"PassengerId\": test_df.PassengerId, \"Transported\": y})\n",
    "submission_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 largest correlations and categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "test_df = pd.read_csv(\"../input/spaceship-titanic/test.csv\")\n",
    "x = test_df[[\"RoomService\", \"Spa\", \"VRDeck\", \"CryoSleep\", \"HomePlanet\"]]\n",
    "\n",
    "x[\"RoomService\"].fillna(x[\"RoomService\"].mean(skipna=True), inplace=True)\n",
    "x[\"Spa\"].fillna(x[\"Spa\"].mean(skipna=True), inplace=True)\n",
    "x[\"VRDeck\"].fillna(x[\"VRDeck\"].mean(skipna=True), inplace=True)\n",
    "\n",
    "x[\"CryoSleep\"] = np.where(x[\"CryoSleep\"].values == True, 2, np.where(x[\"CryoSleep\"].values == False, 0, 1))\n",
    "x[\"HomePlanet\"] = np.where(x[\"HomePlanet\"].values == 'Earth', 3,\n",
    "                               np.where(x[\"HomePlanet\"].values == 'Europa', 2,\n",
    "                                       np.where(x[\"HomePlanet\"].values == 'Mars', 1, 0)))\n",
    "\n",
    "x = np.concatenate((x[\"RoomService\"].values.reshape((len(x[\"RoomService\"].values), 1, 1)),\n",
    "                    x[\"Spa\"].values.reshape((len(x[\"Spa\"].values), 1, 1)),\n",
    "                    x[\"VRDeck\"].values.reshape((len(x[\"VRDeck\"].values), 1, 1)),\n",
    "                    x[\"CryoSleep\"].values.reshape((len(x[\"CryoSleep\"].values), 1, 1)),\n",
    "                    x[\"HomePlanet\"].values.reshape((len(x[\"HomePlanet\"].values), 1, 1))\n",
    "                   ), axis=1)\n",
    "\n",
    "# Normalize the features\n",
    "x[:, 0] = room_normalizer.transform(x[:, 0])\n",
    "x[:, 1] = spa_normalizer.transform(x[:, 1])\n",
    "x[:, 2] = vr_normalizer.transform(x[:, 2])\n",
    "\n",
    "# reshape\n",
    "x = x.reshape((x.shape[0], 5)).astype(np.float16)\n",
    "\n",
    "y = mlp.predict(x)\n",
    "submission_df = pd.DataFrame({\"PassengerId\": test_df.PassengerId, \"Transported\": y})\n",
    "submission_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Including the IdGroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "test_df = pd.read_csv(\"../input/spaceship-titanic/test.csv\")\n",
    "x = test_df[[\"PassengerId\", \"RoomService\", \"Spa\", \"VRDeck\", \"CryoSleep\", \"HomePlanet\"]]\n",
    "\n",
    "group = x.PassengerId.map(get_group)\n",
    "del x['PassengerId']\n",
    "x.insert(0, 'IdGroup', group)\n",
    "\n",
    "x[\"RoomService\"].fillna(x[\"RoomService\"].mean(skipna=True), inplace=True)\n",
    "x[\"Spa\"].fillna(x[\"Spa\"].mean(skipna=True), inplace=True)\n",
    "x[\"VRDeck\"].fillna(x[\"VRDeck\"].mean(skipna=True), inplace=True)\n",
    "\n",
    "x[\"CryoSleep\"] = np.where(x[\"CryoSleep\"].values == True, 2, np.where(x[\"CryoSleep\"].values == False, 0, 1))\n",
    "x[\"HomePlanet\"] = np.where(x[\"HomePlanet\"].values == 'Earth', 3,\n",
    "                               np.where(x[\"HomePlanet\"].values == 'Europa', 2,\n",
    "                                       np.where(x[\"HomePlanet\"].values == 'Mars', 1, 0)))\n",
    "\n",
    "x = np.concatenate((x[\"IdGroup\"].values.reshape((len(x[\"IdGroup\"].values), 1, 1)),\n",
    "                    x[\"RoomService\"].values.reshape((len(x[\"RoomService\"].values), 1, 1)),\n",
    "                    x[\"Spa\"].values.reshape((len(x[\"Spa\"].values), 1, 1)),\n",
    "                    x[\"VRDeck\"].values.reshape((len(x[\"VRDeck\"].values), 1, 1)),\n",
    "                    x[\"CryoSleep\"].values.reshape((len(x[\"CryoSleep\"].values), 1, 1)),\n",
    "                    x[\"HomePlanet\"].values.reshape((len(x[\"HomePlanet\"].values), 1, 1))\n",
    "                   ), axis=1)\n",
    "\n",
    "# Normalize the features\n",
    "x[:, 0] = group_normalizer.transform(x[:, 0])\n",
    "x[:, 1] = room_normalizer.transform(x[:, 1])\n",
    "x[:, 2] = spa_normalizer.transform(x[:, 2])\n",
    "x[:, 3] = vr_normalizer.transform(x[:, 3])\n",
    "\n",
    "# reshape\n",
    "x = x.reshape((x.shape[0], 6)).astype(np.float16)\n",
    "\n",
    "y = mlp.predict(x)\n",
    "submission_df = pd.DataFrame({\"PassengerId\": test_df.PassengerId, \"Transported\": y})\n",
    "submission_df.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e06ff7da33dc9620448857a90ad8b5f428f0d573d205a934d2841c8aee45ea32"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
